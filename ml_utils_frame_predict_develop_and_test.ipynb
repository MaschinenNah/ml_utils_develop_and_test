{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ml_utils_frame_predict_develop_and_test.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "46KM-GCAttm4"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNMmKrbVy5NX7+tPge4ARHT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MaschinenNah/ml_utils_develop_and_test/blob/main/ml_utils_frame_predict_develop_and_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhsH5NLqFnau"
      },
      "source": [
        "### Package ml_utils laden und importieren"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZWw-9ZFZXx8",
        "outputId": "3d8b8828-359f-4b04-ad0e-6ffc0088b265"
      },
      "source": [
        "!git clone https://github.com/MaschinenNah/ml_utils\n",
        "from ml_utils import load\n",
        "from ml_utils import convert\n",
        "from ml_utils import show\n",
        "from ml_utils import frame_predict as fp"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ml_utils'...\n",
            "remote: Enumerating objects: 103, done.\u001b[K\n",
            "remote: Counting objects: 100% (103/103), done.\u001b[K\n",
            "remote: Compressing objects: 100% (73/73), done.\u001b[K\n",
            "remote: Total 103 (delta 44), reused 73 (delta 21), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (103/103), 11.38 KiB | 3.79 MiB/s, done.\n",
            "Resolving deltas: 100% (44/44), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCoov6YTyRxE"
      },
      "source": [
        "### Modul erneut importieren nach lokaler Veränderung"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSA2I4zBq2wy",
        "outputId": "2655b77c-40cb-4586-aba8-c357b694f7b8"
      },
      "source": [
        "import importlib\n",
        "importlib.reload(frame_predict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'ml_utils.load' from '/content/ml_utils/load.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUvkytT_GK1X"
      },
      "source": [
        "from tensorflow.keras.utils import Sequence\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "import random\n",
        "\n",
        "\n",
        "class FramePredictionGenerator(Sequence):\n",
        "\n",
        "  def __init__(self, dir_, frame_shape, n_frames, batch_size=50, validation_fraction=0.1):\n",
        "    random.seed(0)\n",
        "\n",
        "    self.frame_shape = frame_shape\n",
        "    self.n_frames = n_frames\n",
        "    self.batch_size = batch_size\n",
        "    \n",
        "    # Pfade zu allen Verzeichnissen, die Frames einer Szene enthalten:\n",
        "    scene_dir_paths =  load.all_abs_paths_in_dir(dir_)\n",
        "    \n",
        "    # all_examples soll die PFADE zu allen Beispielen speichern. Wenn n_frames = 3, dann so:\n",
        "    # [[frame0, frame1, frame2, frame3],\n",
        "    #  [frame1, frame2, frame3, frame4],\n",
        "    #  [frame2, frame3, frame4, frame5],\n",
        "    #  ...\n",
        "    self.all_examples = []\n",
        "    \n",
        "    # für jede Szene:\n",
        "    for scene_dir_path in scene_dir_paths:\n",
        "      # Pfade zu allen Dateien:\n",
        "      all_frame_paths_in_scene = load.all_abs_paths_in_dir(scene_dir_path)\n",
        "      list.sort(all_frame_paths_in_scene)\n",
        "\n",
        "      # Wie viele Beispiele können aus einer Szene gewonnen werden?\n",
        "      number_of_frames = len(all_frame_paths_in_scene)\n",
        "      number_of_examples = number_of_frames - self.n_frames\n",
        "\n",
        "      # Erzeugung der Beispiele:\n",
        "      for example_index in range(number_of_examples):\n",
        "        example = []\n",
        "        for frame_index in range(self.n_frames+1):\n",
        "          # Berechnung des Indices des aktuellen Beispiels:\n",
        "          index = example_index + frame_index\n",
        "          # Befüllung des Beipiels:\n",
        "          example.append(all_frame_paths_in_scene[index])\n",
        "        # Beispiel anhängen\n",
        "        self.all_examples.append(example)\n",
        "      \n",
        "      # Beispiele mischen, ansonsten stehen sie in der vorgegebenen Reihenfolge in der Liste:\n",
        "      random.shuffle(self.all_examples) \n",
        "\n",
        "      # Der Index der Stelle, die Trainings- und Validierungsbeispiele trennt:\n",
        "      split_index = int(len(self.all_examples) * 1.0 - validation_fraction)\n",
        "\n",
        "      # Trennung der Trainings- von den Validierungsbeispielen:\n",
        "      self.train_examples = self.all_examples[:split_index]\n",
        "      self.validation_examples = self.all_examples[split_index:]\n",
        "\n",
        "      # Ermittlung der Länge des Generators, sprich:\n",
        "      # Wie viele Batches kann der Generator pro Epoche liefern?\n",
        "      self.len = int(len(self)/self.batch_size)\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.len\n",
        "\n",
        "  def __getitem__(self, batch_index):\n",
        "    if batch_index >= self.len:\n",
        "      raise IndexError(\"batch index out of range\")\n",
        "    else:\n",
        "      # Wir erzeugen die Numpy-Arrays, welche die x und y Batches repräsentieren:\n",
        "      batch_x, batch_y = self._get_empty_batches()\n",
        "      # Indices der Beispiele, die in den aktuellen Batch hineingeschrieben werden sollen:\n",
        "      start = int(batch_index * self.batch_size)\n",
        "      stop = int((batch_index + 1) * self.batch_size)\n",
        "      # Auswahl der Beispiele:\n",
        "      selection = self.train_examples[start:stop]\n",
        "      \n",
        "      # Ausgehend von den Pfaden in den ausgewählten Beispielen...\n",
        "      for example_idx, example in enumerate(selection):\n",
        "        # Befüllen von batch_x:\n",
        "        for frame_idx, img_path in enumerate(example[:-1]):\n",
        "          img = Image.open(img_path)\n",
        "          batch_x[example_idx, frame_idx] = load.img_path_to_np_array(img_path)\n",
        "        # Befüllen von batch_y:\n",
        "        img_path = example[-1]\n",
        "        batch_y[example_idx] = load.img_path_to_np_array(img_path)\n",
        "\n",
        "    return batch_x, batch_y\n",
        "\n",
        "  # on_epoch_end wird automatisch nach jeder Epoche aufgerufen und mischt die Beispiele:\n",
        "  def on_epoch_end(self):\n",
        "    random.shuffle(self.train_examples)\n",
        "\n",
        "  # Hilfsfunktion – Erzeugung leerer Batches:\n",
        "  def _get_empty_batches(self):\n",
        "    empty_batch_x = np.empty((self.batch_size,) + (self.n_frames,) + (self.frame_shape), \"float32\")\n",
        "    empty_batch_y = np.empty((self.batch_size,) + (self.frame_shape), \"float32\")\n",
        "    return empty_batch_x, empty_batch_y\n",
        "\n",
        "  # Liefert die Daten, um einen Validierungs-Generator zu bauen:\n",
        "  def get_validation_data(self):\n",
        "    return self.validation_examples, self.frame_shape, self.batch_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqHdFhWSAjuo"
      },
      "source": [
        "### Modul show auf GitHub aktualisieren"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NZl7BtYtVir"
      },
      "source": [
        "import getpass\n",
        "\n",
        "def commit_to_github(file, message):\n",
        "  github_pw = getpass.getpass();\n",
        "  %cd /content/ml_utils\n",
        "  !git config --global user.email \"maschinennah@gmail.com\"\n",
        "  !git config --global user.name \"MaschinenNah\"\n",
        "  !git add $file\n",
        "  !git commit -m $message\n",
        "  !git remote rm origin\n",
        "  !git remote add origin https://MaschinenNah:{github_pw}@github.com/MaschinenNah/ml_utils.git\n",
        "  !git push -u origin main\n",
        "  %cd /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_BE-JW9nZWk",
        "outputId": "6362761e-a7fb-402d-d1f7-740e5ee12d8f"
      },
      "source": [
        "commit_to_github(\"frame_predict.py\", \"rename\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "··········\n",
            "/content/ml_utils\n",
            "[main 50db331] rename\n",
            " 1 file changed, 1 insertion(+)\n",
            " create mode 100644 frame_predict.py\n",
            "Counting objects: 2, done.\n",
            "Delta compression using up to 2 threads.\n",
            "Compressing objects: 100% (2/2), done.\n",
            "Writing objects: 100% (2/2), 224 bytes | 224.00 KiB/s, done.\n",
            "Total 2 (delta 1), reused 0 (delta 0)\n",
            "remote: Resolving deltas: 100% (1/1), completed with 1 local object.\u001b[K\n",
            "To https://github.com/MaschinenNah/ml_utils.git\n",
            "   5678e54..50db331  main -> main\n",
            "Branch 'main' set up to track remote branch 'main' from 'origin'.\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}